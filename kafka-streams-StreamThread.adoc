== [[StreamThread]] StreamThread -- Stream Processor Thread

`StreamThread` is the *stream processor thread* in a KafkaStreams application.

`StreamThread` is simply a <<run, thread of execution>> (i.e. Java's https://docs.oracle.com/javase/9/docs/api/java/lang/Thread.html[Thread]) that...FIXME

.StreamThread and Stream Processing
image::images/kafka-streams-StreamThread.png[align="center"]

`StreamThread` is <<create, created>> exclusively when `KafkaStreams` is link:kafka-streams-KafkaStreams.adoc#creating-instance[created].

NOTE: `KafkaStreams` uses link:kafka-streams-KafkaStreams.adoc#threads[num.stream.threads] configuration property for the number of `StreamThreads` to create.

[[pollTimeMs]]
`StreamThread` uses link:kafka-streams-properties.adoc#poll.ms[poll.ms] configuration property as the *polling interval* for <<pollRequests, polling the topics for records>>.

`StreamThread` uses the Kafka <<consumer, consumer>> to:

* Subscribe to topics (with <<rebalanceListener, RebalanceListener>>) right after `StreamThread` has been requested to <<runLoop, run the main event loop>>

* Poll the topics subscribed (and fetch records if available) right after `StreamThread` has been requested to <<pollRequests, get the next batch of records by polling>>

* <<resetInvalidOffsets, resetInvalidOffsets>> (when an `InvalidOffsetException` is reported while <<pollRequests, polling the topics for records>>)

`StreamThread` closes the Kafka <<consumer, consumer>> while <<completeShutdown, shuting down>>.

[[internal-registries]]
.StreamThread's Internal Properties (e.g. Registries, Counters and Flags)
[cols="1,2",options="header",width="100%"]
|===
| Name
| Description

| [[builder]] `builder`
| link:kafka-streams-InternalTopologyBuilder.adoc[InternalTopologyBuilder]

| [[rebalanceListener]] `rebalanceListener`
a| link:kafka-streams-StreamThread-RebalanceListener.adoc[RebalanceListener]

* Used exclusively when `StreamThread` is requested to <<runLoop, run the main event loop>> (and requests the Kafka <<consumer, Consumer>> to subscribe to get dynamically assigned partitions of topics matching specified pattern)

NOTE: `StreamThread` requests <<builder, InternalTopologyBuilder>> for the link:kafka-streams-InternalTopologyBuilder.adoc#sourceTopicPattern[source topic pattern] to subscribe to.

| [[timerStartedMs]] `timerStartedMs`
| The timestamp when the timer has started
|===

[[logging]]
[TIP]
====
Enable any of `WARN`, `ERROR`, `INFO`, `DEBUG`, `TRACE` logging levels for `org.apache.kafka.streams.processor.internals.StreamThread` logger to see what happens inside.

Add the following line to `log4j.properties`:

```
log4j.logger.org.apache.kafka.streams.processor.internals.StreamThread=TRACE
```

Refer to link:kafka-logging.adoc#log4j.properties[Application Logging Using log4j].
====

=== [[processAndMaybeCommit]] `processAndMaybeCommit` Internal Method

[source, java]
----
long processAndMaybeCommit(final long recordsProcessedBeforeCommit)
----

`processAndMaybeCommit`...FIXME

NOTE: `processAndMaybeCommit` is used exclusively when `StreamThread` is requested for <<runOnce, polling records once>> (and there have been records to be processed).

=== [[pollRequests]] Polling for Records -- `pollRequests` Internal Method

[source, java]
----
ConsumerRecords<byte[], byte[]> pollRequests(final long pollTimeMs)
----

`pollRequests`...FIXME

[NOTE]
====
`pollRequests` is used exclusively when `StreamThread` is requested to <<runOnce, consume records once>>:

* With `0` for `pollTimeMs` when in `PARTITIONS_ASSIGNED` <<state, state>>

* With <<pollTimeMs, pollTimeMs>> in any other state but `PARTITIONS_ASSIGNED`
====

=== [[resetInvalidOffsets]] `resetInvalidOffsets` Internal Method

[source, java]
----
void resetInvalidOffsets(final InvalidOffsetException e)
----

`resetInvalidOffsets`...FIXME

NOTE: `resetInvalidOffsets` is used exclusively when `StreamThread` is requested to <<pollRequests, pollRequests>> (and an `InvalidOffsetException` is reported).

=== [[completeShutdown]] `completeShutdown` Internal Method

[source, java]
----
void completeShutdown(final boolean cleanRun)
----

`completeShutdown`...FIXME

NOTE: `completeShutdown` is used when...FIXME

=== [[runOnce]] Polling Records Once -- `runOnce` Method

[source, java]
----
long runOnce(final long recordsProcessedBeforeCommit)
----

`runOnce` does...FIXME

[NOTE]
====
`recordsProcessedBeforeCommit` starts as `UNLIMITED_RECORDS`, i.e. `-1` in <<runLoop, runLoop>> (where the record stream processing starts off), and is passed along to every invocation of `runOnce`.

`runOnce` can <<adjustRecordsProcessedBeforeCommit, adjust>> `recordsProcessedBeforeCommit` (i.e. scale it down or up) given the current processing latency and commit time.

Eventually, `recordsProcessedBeforeCommit` reaches <<processAndMaybeCommit, processAndMaybeCommit>>.
====

Internally, `runOnce` first <<runOnce-branches-state, branches off>> per <<state, state>>.

[[runOnce-branches-state]]
.runOnce's State Branches
[cols="1,2",options="header",width="100%"]
|===
| PARTITIONS_ASSIGNED
| Other states

a|

1. `runOnce` <<pollRequests, pollRequests>> with timeout `0`

1. Requests <<taskManager, TaskManager>> to link:kafka-streams-TaskManager.adoc#updateNewAndRestoringTasks[updateNewAndRestoringTasks]

  i. (optionally) Changes the <<state, state>> to `RUNNING`

a|

1. `runOnce` <<pollRequests, pollRequests>> with timeout as defined by <<pollTimeMs, poll.ms>> configuration property

1. If (for some reason) the <<state, state>> has changed to `PARTITIONS_ASSIGNED` `runOnce` requests <<taskManager, TaskManager>> to link:kafka-streams-TaskManager.adoc#updateNewAndRestoringTasks[updateNewAndRestoringTasks]

  i. (optionally) Changes the <<state, state>> to `RUNNING`
|===

If there are records to processed (i.e. <<pollRequests, pollRequests>> gave records) and the <<taskManager, TaskManager>> has link:kafka-streams-TaskManager.adoc#hasActiveRunningTasks[active running tasks], `runOnce` requests `pollTimeSensor` to record the current poll latency.

`runOnce` <<addRecordsToTasks, addRecordsToTasks>> followed by <<processAndMaybeCommit, processAndMaybeCommit>> (with the input number of records as `recordsProcessedBeforeCommit`).

With at least one record processed (as computed in <<processAndMaybeCommit, processAndMaybeCommit>>) `runOnce` requests `processTimeSensor` to record the current process latency and <<adjustRecordsProcessedBeforeCommit, adjustRecordsProcessedBeforeCommit>>.

CAUTION: FIXME How would you name the block above with the records polled and `taskManager.hasActiveRunningTasks()`? What's the purpose of the above?

`runOnce` <<punctuate, punctuate>>

`runOnce` <<maybeCommit, maybeCommit>> (with <<timerStartedMs, timerStartedMs>>)

`runOnce` <<maybeUpdateStandbyTasks, maybeUpdateStandbyTasks>> (with <<timerStartedMs, timerStartedMs>>)

NOTE: `runOnce` is used exclusively when `StreamThread` is requested to <<runLoop, run main event loop>>.

=== [[addRecordsToTasks]] `addRecordsToTasks` Internal Method

[source, java]
----
void addRecordsToTasks(final ConsumerRecords<byte[], byte[]> records)
----

`addRecordsToTasks`...FIXME

NOTE: `addRecordsToTasks` is used exclusively when `StreamThread` is requested to <<runOnce, consume records once>>.

=== [[maybeUpdateStandbyTasks]] `maybeUpdateStandbyTasks` Internal Method

[source, java]
----
void maybeUpdateStandbyTasks(final long now)
----

`maybeUpdateStandbyTasks`...FIXME

NOTE: `maybeUpdateStandbyTasks` is used exclusively when `StreamThread` is requested to <<runOnce, consume records once>>.

=== [[maybeCommit]] `maybeCommit` Method

[source, java]
----
void maybeCommit(final long now)
----

`maybeCommit`...FIXME

NOTE: `maybeCommit` is used when...FIXME

=== [[punctuate]] `punctuate` Internal Method

[source, java]
----
void punctuate()
----

`punctuate`...FIXME

NOTE: `punctuate` is used when...FIXME

=== [[create]] Creating StreamThread -- `create` Factory Method

[source, java]
----
StreamThread create(
  final InternalTopologyBuilder builder,
  final StreamsConfig config,
  final KafkaClientSupplier clientSupplier,
  final AdminClient adminClient,
  final UUID processId,
  final String clientId,
  final Metrics metrics,
  final Time time,
  final StreamsMetadataState streamsMetadataState,
  final long cacheSizeBytes,
  final StateDirectory stateDirectory,
  final StateRestoreListener userStateRestoreListener)
----

`create`...FIXME

NOTE: `create` is used exclusively when `KafkaStreams` is link:kafka-streams-KafkaStreams.adoc#creating-instance[created].

=== [[creating-instance]] Creating StreamThread Instance

`StreamThread` takes the following when created:

* [[time]] `Time`
* [[config]] link:kafka-streams-StreamsConfig.adoc[StreamsConfig]
* [[restoreConsumer]] Restore Kafka consumer (of keys and values as array of bytes)
* [[consumer]] Kafka https://kafka.apache.org/10/javadoc/org/apache/kafka/clients/consumer/KafkaConsumer.html[Consumer] (of keys and values as array of bytes)
* [[originalReset]] `originalReset`
* [[taskManager]] link:kafka-streams-TaskManager.adoc[TaskManager]
* [[streamsMetrics]] `StreamsMetricsThreadImpl`
* [[builder]] link:kafka-streams-InternalTopologyBuilder.adoc[InternalTopologyBuilder]
* [[threadClientId]] `threadClientId`
* [[logContext]] `LogContext`

`StreamThread` initializes the <<internal-registries, internal registries and counters>>.

=== [[runLoop]] Running Main Event Loop -- `runLoop` Internal Method

[source, java]
----
void runLoop()
----

`runLoop` requests <<consumer, Consumer>> to subscribe to the link:kafka-streams-InternalTopologyBuilder.adoc#sourceTopicPattern[source topics] (from <<builder, InternalTopologyBuilder>>) with <<rebalanceListener, ConsumerRebalanceListener>>.

`runLoop` <<runOnce, runs once>> in a loop (as long as <<isRunning, isRunning>> flag is turned on).

In case of `TaskMigratedException`, `runLoop` prints out the following WARN message to the logs.

```
Detected a task that got migrated to another thread. This implies that this thread missed a rebalance and dropped out of the consumer group. Trying to rejoin the consumer group now.
```

NOTE: `runLoop` is used exclusively when `StreamThread` is <<run, started>>.

=== [[isRunning]] `isRunning` Method

[source, java]
----
boolean isRunning()
----

`isRunning`...FIXME

NOTE: `isRunning` is used when...FIXME

=== [[run]] Starting Stream Processor Thread -- `run` Method

[source, java]
----
void run()
----

NOTE: `run` is part of Java's https://docs.oracle.com/javase/9/docs/api/java/lang/Thread.html#run--[Thread Contract] to be executed by a JVM thread.

Internally, `run` prints out the following INFO message to the logs.

```
Starting
```

`run` <<setState, sets the state>> to `RUNNING` and <<runLoop, runs the processing loop>>.

At the end, `run` <<completeShutdown, shuts down>> (per `cleanRun` flag that says whether <<runLoop, running the loop>> stopped cleanly or not).

`run` re-throws any `KafkaException`.

`run` prints out the following ERROR message to the logs for any other `Exception`.

```
Encountered the following error during processing: [exception]
```

NOTE: `run` is used when `KafkaStreams` is link:kafka-streams-KafkaStreams.adoc#start[started].

=== [[setState]] Setting State -- `setState` Method

[source, java]
----
boolean setState(final State newState)
----

`setState`...FIXME

NOTE: `setState` is used when...FIXME

=== [[adjustRecordsProcessedBeforeCommit]] Scaling Up or Down (Per Current Processing Latency and Commit Time) -- `adjustRecordsProcessedBeforeCommit` Internal Method

[source, java]
----
long adjustRecordsProcessedBeforeCommit(
  final long prevRecordsProcessedBeforeCommit,
  final long totalProcessed,
  final long processLatency, final long commitTime)
----

`adjustRecordsProcessedBeforeCommit` scales (adjusts) the number of records (`recordsProcessedBeforeCommit`) up or down per current `processLatency` and `commitTime` times.

If `processLatency` is greater than `0` and `commitTime`, `adjustRecordsProcessedBeforeCommit` scales `recordsProcessedBeforeCommit` down and prints out the following DEBUG message to the logs:

```
processing latency [processLatency] > commit time [commitTime] for [totalProcessed] records. Adjusting down recordsProcessedBeforeCommit=[recordsProcessedBeforeCommit]
```

If however `prevRecordsProcessedBeforeCommit` is available (measured) and `processLatency` is greater than `0` (but not `commitTime`), `adjustRecordsProcessedBeforeCommit` scales `recordsProcessedBeforeCommit` up and prints out the following DEBUG message to the logs:

```
processing latency [processLatency] < commit time [commitTime] for [totalProcessed] records. Adjusting up recordsProcessedBeforeCommit=[recordsProcessedBeforeCommit]
```

NOTE: `adjustRecordsProcessedBeforeCommit` is used exclusively when `StreamThread` is requested to <<runOnce, poll records once>> (and there have been records available).

=== [[toString]] Describing Itself (Text Representation) -- `toString` Method

[source, java]
----
String toString() // <1>
String toString(final String indent)
----
<1> Calls `toString(final String indent)` with an empty indent, i.e. `""`

`toString` gives a text representation with "StreamsThread threadId:" and the thread name followed by the link:kafka-streams-TaskManager.adoc#toString[text representation] of the <<taskManager, TaskManager>>.

[source, scala]
----
FIXME toString in action
----

NOTE: `toString` is used when `KafkaStreams` is requested to link:kafka-streams-KafkaStreams.adoc#toString[describe itself].
